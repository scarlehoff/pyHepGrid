README 
(Incomplete, and always will be. The grid is a mysterious thing...)

###################################################################################################
Follow certificate setup as per Jeppe's tutorial @
https://www.ippp.dur.ac.uk/~andersen/GridTutorial/gridtutorial.html

Make a careful note of passwords (can get confusing). Don't use passwords used elsewhere in case you
want to automate proxy renewal (like me and Juan)

###################################################################################################
NNLOJET setup:
As usual - pull the NNLOJET repository, update to modules and make -jXX
YOU MUST INSTALL WITH LHAPDF-6.1.6. 6.2.1 IS BROKEN, and will not work on the grid outside of Durham(!) 
-> When installing lhapdf, don't have the default prefix $HOME for installation as the entire home 
   directory will be tarred up when initialising the grid libraries for LHAPDF(!)
-> For this you will also need to install and link against boost (painful I know...)

###################################################################################################
LFN SETUP
put this into your bashrc:
export CC=gcc
export XX=g++
export LCG_CATALOG_TYPE="lfc"
export LFC_HOME=/grid/pheno/<LFN_NAME>
export LFC_HOST="lfc01.dur.scotgrid.ac.uk"
source /opt/rh/devtoolset-4/enable              # Default gcc is version 4 and this DOES NOT WORK!

then
source ~/.bashrc

create lfndir
lfc-mkdir /grid/pheno/<LFN_NAME>

lfc-mkdir input
lfc-mkdir output
lfc-mkdir warmup

should be able to see the following using lfc-ls
input
output
warmup

generate more directories in analogy. A nice wrapper is included as described in the GRID 
	 STORAGE MANAGEMENT section later on.

###################################################################################################
GRID SCRIPTS SETUP [GANGALESS]

stored in repo ssh://<hepforgeuser>@login.hepforge.prg//hepforge/hg/nnlojet/private/grid

gangaless_resources: create own header, copy template header
adjust personal header
adjust headername in general header.py file (only add the name of your header file to top)
create folder for runcard storage and add to header file (e.g NNLOJET/driver/grid/)

add yourname_header.py file and altered header.py file to the repo, and COMMIT

generate runcard.py following template_runcard.py example

############ PROXY SETUP ##########
By default, jobs will fail if the proxy ends before they finish running, so it's a good idea 
to keep them synced with new proxies as you need:

By hand: 
=> Create new proxy
|-> arcproxy -S pheno -N -c validityPeriod=24h -c vomsACvalidityPeriod=24h
=> Sync current jobs with latest proxy
|-> arcsync -c ce1.dur.scotgrid.ac.uk
|-> arcrenew -a

Automated (set & forget):
I've added some proxy automation scripts to the repo in gangaless_resources/proxy_renewal/
To get these working, simply add your certificate password in to .script2.exp (plaintext I 
   know, so it's bad...)
Make sure .proxy.sh is set up for your user (directories should point to your gangaless resources)
-> Run by hand to check (shouldn't need your password)
Then set up .proxy.sh to run as a cron job at least once per day (I suggest 2x in case of failure)

############ GRID SCRIPTS USAGE ############

initialise libraries [LHAPDF,(OPENLOOPS?)]
python3 main.py ini -L 

initialise runcard
python3 main ini runcard.py -Bn -w warmup.file
 -B is production in arc -D in dirac
 -A is warmup in arc 

send the jobs with one of:
python3 main.py run runcard.py -An # ARC WARMUP
python3 main.py run runcard.py -Bn # ARC PRODUCTION
python3 main.py run runcard.py -Dn # DIRAC PRODUCTION

manage the jobs with:
python3 main.py man runcard.py -(A/B/D)n

For running anything on the grid, the help text in main.py (python3 main.py -h) is useful for 
hidden options that aren't all necessarily documented(!)

#######################################
Finalising results [Juan, can we have your input on your setup here?]
-> The process of pulling the production results from grid storage to the gridui
-> You have a choice of setups for this (or you can implement your own)
=> DUNCAN'S SETUP
       ./finalise.py 
   or 
   set finalisation_script = "finalise" in your header and 
       ./main.py man --get_data
   This will find all of the runcards specified at the top of finalise_runcard.py (or 
   other as specified in finalise_runcards) and pull all of the data it can find for them 
   from the grid storage. 
   The output will be stored in production_base_dir (as set in the header) with one folder 
   for each set of runs, and the prefix as set in finalise_prefix. Corrupted data in the 
   grid storage will be deleted.
=> JUAN'S SETUP
   ???
=> CUSTOM SETUPS
   For your own custom setup, you just need to write a finalisation script which exposes a
   function called do_finalise(). This function does the pulling from the grid storage. You
   then set the variable finalisation_script to the name of your script (without the .py suffix)
   Happy days!

 [./finalise.py, ./main.py man --get_data]

#######################################
WORKFLOW

1) initialise warmup runcard
2) run warmup runcard
3) switch warmup -> production in runcard
4) When warmup complete, reinitialise runcard for production
5) run production runcard as many times as you like w/ different seeds
6) pull down the results (finalisation)

#######################################
DURHAM ARC MONITORING WEBSITE
https://grafana.dur.scotgrid.ac.uk/dashboard/db/uki-scotgrid-durham-grid-queues?refresh=15s&orgId=1

DIRAC MONITORING WEBSITE
https://dirac.gridpp.ac.uk:8443/DIRAC/

#######################################
GRID STORAGE MANAGEMENT
I've written a wrapper to the lfn commands (lscp.py) in order to simplify manual navigation of
the LFN filesystem, stored in useful_bits_and_bobs/duncan/grid_helpers/ (I suggest adding it to
your path or symlinking it somewhere nice)
Usage:
	lscp.py <lfn_dir> -s <file search terms> -r <file reject terms> 
		[-cp (copy to gridui)] [-rm (delete from grid storage)] [-j (# threads)]
		[-cpg (copy from gridui to storage)]

More info is given in the helptext (lscp.py -h)